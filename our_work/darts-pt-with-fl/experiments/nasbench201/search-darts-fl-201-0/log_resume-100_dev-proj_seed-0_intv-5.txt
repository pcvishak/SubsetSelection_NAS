2022-03-23 20:28:50,215 args = Namespace(arch_learning_rate=0.0003, arch_weight_decay=0.001, batch_size=64, ckpt_interval=20, cutout=False, cutout_length=16, cutout_prob=1.0, data='../data', dataset='cifar10', dev='proj', edge_decision='random', epochs=100, expid_tag='none', fast=False, gpu='auto', grad_clip=5, init_channels=16, layers=8, learning_rate=0.025, learning_rate_min=0.001, log_tag='', method='darts-proj', model_path='saved_models', momentum=0.9, proj_crit='acc', proj_intv=5, report_freq=50, resume_epoch=100, resume_expid='search-darts-fl-201-0', save='../experiments/nasbench201/search-darts-fl-201-0', search_space='nas-bench-201', seed=0, train_portion=0.5, weight_decay=0.0003)
2022-03-23 20:28:50,215 gpu device = 0
2022-03-23 20:29:16,910 param size = 1.686106MB
2022-03-23 20:29:18,489 loading checkpoint from darts-proj-fl-201
2022-03-23 20:29:18,489 => loading checkpoint '../experiments/nasbench201/search-darts-fl-201-0/checkpoint_100.pth.tar'
2022-03-23 20:29:18,679 => loaded checkpoint '../experiments/nasbench201/search-darts-fl-201-0/checkpoint_100.pth.tar' (epoch 99)
2022-03-23 20:29:43,028 tensor([[0.0901, 0.4809, 0.0983, 0.1123, 0.2184],
        [0.0869, 0.4536, 0.1065, 0.1138, 0.2392],
        [0.1355, 0.3822, 0.1406, 0.1068, 0.2349],
        [0.0714, 0.4604, 0.1173, 0.1342, 0.2168],
        [0.0853, 0.3909, 0.2005, 0.1161, 0.2072],
        [0.0856, 0.4116, 0.1652, 0.1185, 0.2191]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 20:30:05,732 train_acc  74.947998
2022-03-23 20:30:05,733 train_loss 0.841762
2022-03-23 20:30:28,443 valid_acc  70.503998
2022-03-23 20:30:28,443 valid_loss 0.983107
2022-03-23 20:30:28,446 epoch 0
2022-03-23 20:30:28,446 project
2022-03-23 20:30:54,148 valid_acc 68.383995
2022-03-23 20:30:54,149 valid_loss 1.034160
2022-03-23 20:31:19,608 valid_acc 52.576000
2022-03-23 20:31:19,608 valid_loss 2.085155
2022-03-23 20:31:45,033 valid_acc 46.219997
2022-03-23 20:31:45,033 valid_loss 1.893009
2022-03-23 20:32:10,643 valid_acc 57.567997
2022-03-23 20:32:10,643 valid_loss 1.387383
2022-03-23 20:32:36,204 valid_acc 64.855995
2022-03-23 20:32:36,205 valid_loss 1.306198
2022-03-23 20:32:36,205 best opid 2
2022-03-23 20:32:36,206 tensor([[0.0901, 0.4809, 0.0983, 0.1123, 0.2184],
        [0.0869, 0.4536, 0.1065, 0.1138, 0.2392],
        [0.1355, 0.3822, 0.1406, 0.1068, 0.2349],
        [0.0714, 0.4604, 0.1173, 0.1342, 0.2168],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0856, 0.4116, 0.1652, 0.1185, 0.2191]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 20:32:36,733 train 000 4.486150e+00 23.437500 50.000000
2022-03-23 20:32:53,750 train 050 2.315679e+00 34.191177 84.068634
2022-03-23 20:33:10,721 train 100 1.876190e+00 41.692451 88.335396
2022-03-23 20:33:27,648 train 150 1.675180e+00 45.757450 90.262833
2022-03-23 20:33:44,671 train 200 1.551438e+00 48.927238 91.480095
2022-03-23 20:34:01,678 train 250 1.461073e+00 51.525150 92.355583
2022-03-23 20:34:18,604 train 300 1.392081e+00 53.457226 93.090736
2022-03-23 20:34:35,688 train 350 1.337021e+00 55.021366 93.589745
2022-03-23 20:34:49,312 tensor([[0.0908, 0.4824, 0.1003, 0.1165, 0.2099],
        [0.0859, 0.4585, 0.1065, 0.1150, 0.2341],
        [0.1334, 0.3856, 0.1412, 0.1080, 0.2318],
        [0.0702, 0.4665, 0.1158, 0.1358, 0.2118],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0836, 0.4176, 0.1639, 0.1189, 0.2159]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 20:35:12,400 train_acc  66.823997
2022-03-23 20:35:12,400 train_loss 0.932618
2022-03-23 20:35:35,305 valid_acc  65.903999
2022-03-23 20:35:35,305 valid_loss 0.968278
2022-03-23 20:35:35,305 epoch 1
2022-03-23 20:35:35,707 train 000 1.299197e+00 56.224068 93.951485
2022-03-23 20:35:52,764 train 050 1.258127e+00 57.444099 94.307251
2022-03-23 20:36:09,824 train 100 1.222713e+00 58.441395 94.673279
2022-03-23 20:36:26,816 train 150 1.191794e+00 59.418995 94.974617
2022-03-23 20:36:43,657 train 200 1.165197e+00 60.236637 95.193321
2022-03-23 20:37:00,574 train 250 1.140429e+00 61.051041 95.412041
2022-03-23 20:37:17,502 train 300 1.117942e+00 61.801918 95.585579
2022-03-23 20:37:34,481 train 350 1.100425e+00 62.360947 95.689362
2022-03-23 20:37:48,096 tensor([[0.0916, 0.4828, 0.1007, 0.1199, 0.2051],
        [0.0860, 0.4605, 0.1068, 0.1161, 0.2306],
        [0.1330, 0.3864, 0.1420, 0.1096, 0.2290],
        [0.0699, 0.4690, 0.1160, 0.1369, 0.2082],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0830, 0.4193, 0.1638, 0.1209, 0.2130]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 20:38:10,973 train_acc  72.323997
2022-03-23 20:38:10,973 train_loss 0.788040
2022-03-23 20:38:33,750 valid_acc  70.820000
2022-03-23 20:38:33,751 valid_loss 0.841841
2022-03-23 20:38:33,751 epoch 2
2022-03-23 20:38:34,105 train 000 1.086254e+00 62.825584 95.809372
2022-03-23 20:38:51,048 train 050 1.067849e+00 63.433086 95.948479
2022-03-23 20:39:08,042 train 100 1.052827e+00 63.934540 96.057663
2022-03-23 20:39:24,912 train 150 1.039710e+00 64.373825 96.150101
2022-03-23 20:39:41,826 train 200 1.029039e+00 64.773163 96.220413
2022-03-23 20:39:58,659 train 250 1.016730e+00 65.106560 96.332344
2022-03-23 20:40:15,595 train 300 1.004294e+00 65.520325 96.431046
2022-03-23 20:40:32,488 train 350 9.932023e-01 65.883751 96.521034
2022-03-23 20:40:45,974 tensor([[0.0925, 0.4819, 0.1010, 0.1232, 0.2012],
        [0.0865, 0.4615, 0.1073, 0.1173, 0.2273],
        [0.1336, 0.3862, 0.1429, 0.1111, 0.2261],
        [0.0699, 0.4707, 0.1166, 0.1374, 0.2055],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0830, 0.4192, 0.1653, 0.1229, 0.2097]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 20:41:08,685 train_acc  74.972000
2022-03-23 20:41:08,685 train_loss 0.712084
2022-03-23 20:41:31,479 valid_acc  73.127998
2022-03-23 20:41:31,480 valid_loss 0.779956
2022-03-23 20:41:31,480 epoch 3
2022-03-23 20:41:31,827 train 000 9.848732e-01 66.168869 96.585579
2022-03-23 20:41:48,805 train 050 9.766968e-01 66.414955 96.647240
2022-03-23 20:42:05,702 train 100 9.659029e-01 66.737457 96.720024
2022-03-23 20:42:22,520 train 150 9.573792e-01 67.037941 96.769585
2022-03-23 20:42:39,333 train 200 9.490873e-01 67.319946 96.831467
2022-03-23 20:42:56,262 train 250 9.421815e-01 67.543709 96.883514
2022-03-23 20:43:13,203 train 300 9.355393e-01 67.748024 96.933083
2022-03-23 20:43:29,986 train 350 9.276885e-01 68.019989 96.996841
2022-03-23 20:43:43,483 tensor([[0.0930, 0.4837, 0.1008, 0.1262, 0.1963],
        [0.0863, 0.4642, 0.1073, 0.1174, 0.2249],
        [0.1330, 0.3877, 0.1436, 0.1116, 0.2242],
        [0.0695, 0.4746, 0.1157, 0.1373, 0.2029],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0823, 0.4211, 0.1651, 0.1243, 0.2071]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 20:44:06,356 train_acc  75.771996
2022-03-23 20:44:06,356 train_loss 0.699534
2022-03-23 20:44:29,140 valid_acc  72.832001
2022-03-23 20:44:29,141 valid_loss 0.775169
2022-03-23 20:44:29,141 epoch 4
2022-03-23 20:44:29,487 train 000 9.221750e-01 68.180367 97.028900
2022-03-23 20:44:46,313 train 050 9.153208e-01 68.418808 97.075455
2022-03-23 20:45:03,279 train 100 9.092329e-01 68.641045 97.111702
2022-03-23 20:45:20,235 train 150 9.028640e-01 68.849396 97.159508
2022-03-23 20:45:37,038 train 200 8.973355e-01 68.995430 97.209915
2022-03-23 20:45:53,933 train 250 8.907382e-01 69.241112 97.247208
2022-03-23 20:46:10,989 train 300 8.855411e-01 69.427490 97.281662
2022-03-23 20:46:27,883 train 350 8.809753e-01 69.572289 97.312683
2022-03-23 20:46:41,380 tensor([[0.0932, 0.4858, 0.1009, 0.1275, 0.1926],
        [0.0858, 0.4688, 0.1067, 0.1167, 0.2220],
        [0.1324, 0.3905, 0.1427, 0.1122, 0.2222],
        [0.0688, 0.4799, 0.1147, 0.1369, 0.1997],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0816, 0.4240, 0.1646, 0.1254, 0.2043]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 20:47:04,207 train_acc  76.203995
2022-03-23 20:47:04,207 train_loss 0.673960
2022-03-23 20:47:26,850 valid_acc  73.883995
2022-03-23 20:47:26,851 valid_loss 0.749547
2022-03-23 20:47:26,851 epoch 5
2022-03-23 20:47:26,851 project
2022-03-23 20:47:52,488 valid_acc 74.379997
2022-03-23 20:47:52,489 valid_loss 0.732805
2022-03-23 20:48:18,330 valid_acc 21.935999
2022-03-23 20:48:18,331 valid_loss 3.526237
2022-03-23 20:48:44,048 valid_acc 62.751999
2022-03-23 20:48:44,048 valid_loss 1.101639
2022-03-23 20:49:09,867 valid_acc 50.695999
2022-03-23 20:49:09,868 valid_loss 1.482210
2022-03-23 20:49:35,450 valid_acc 68.503998
2022-03-23 20:49:35,450 valid_loss 0.919063
2022-03-23 20:49:35,450 best opid 1
2022-03-23 20:49:35,451 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0858, 0.4688, 0.1067, 0.1167, 0.2220],
        [0.1324, 0.3905, 0.1427, 0.1122, 0.2222],
        [0.0688, 0.4799, 0.1147, 0.1369, 0.1997],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0816, 0.4240, 0.1646, 0.1254, 0.2043]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 20:49:35,796 train 000 8.776028e-01 69.697914 97.328568
2022-03-23 20:49:52,708 train 050 8.900371e-01 69.261833 97.205757
2022-03-23 20:50:09,568 train 100 8.919371e-01 69.171028 97.193153
2022-03-23 20:50:26,415 train 150 8.927346e-01 69.120926 97.198212
2022-03-23 20:50:43,235 train 200 8.914612e-01 69.162361 97.212471
2022-03-23 20:51:00,093 train 250 8.909273e-01 69.184204 97.214035
2022-03-23 20:51:17,129 train 300 8.891679e-01 69.257057 97.230766
2022-03-23 20:51:34,017 train 350 8.884178e-01 69.259613 97.241364
2022-03-23 20:51:47,475 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0919, 0.4531, 0.1150, 0.1284, 0.2115],
        [0.1445, 0.3721, 0.1522, 0.1219, 0.2092],
        [0.0727, 0.4654, 0.1216, 0.1488, 0.1916],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0864, 0.4065, 0.1752, 0.1383, 0.1937]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 20:52:10,073 train_acc  73.108002
2022-03-23 20:52:10,074 train_loss 0.775015
2022-03-23 20:52:32,823 valid_acc  71.007996
2022-03-23 20:52:32,823 valid_loss 0.835998
2022-03-23 20:52:32,823 epoch 6
2022-03-23 20:52:33,164 train 000 8.865387e-01 69.327087 97.251839
2022-03-23 20:52:49,930 train 050 8.842857e-01 69.400513 97.270721
2022-03-23 20:53:06,728 train 100 8.818958e-01 69.481163 97.282440
2022-03-23 20:53:23,580 train 150 8.785076e-01 69.587379 97.309349
2022-03-23 20:53:40,425 train 200 8.763422e-01 69.648911 97.325989
2022-03-23 20:53:57,300 train 250 8.738371e-01 69.744194 97.337173
2022-03-23 20:54:14,187 train 300 8.716385e-01 69.831741 97.352654
2022-03-23 20:54:31,029 train 350 8.691767e-01 69.907341 97.372787
2022-03-23 20:54:44,499 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0932, 0.4494, 0.1177, 0.1341, 0.2057],
        [0.1470, 0.3702, 0.1532, 0.1253, 0.2044],
        [0.0733, 0.4650, 0.1220, 0.1525, 0.1873],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0865, 0.4034, 0.1775, 0.1437, 0.1889]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 20:55:07,295 train_acc  76.187996
2022-03-23 20:55:07,295 train_loss 0.690456
2022-03-23 20:55:29,982 valid_acc  74.435997
2022-03-23 20:55:29,982 valid_loss 0.744932
2022-03-23 20:55:29,982 epoch 7
2022-03-23 20:55:30,326 train 000 8.675563e-01 69.961273 97.384956
2022-03-23 20:55:47,186 train 050 8.647767e-01 70.061813 97.399361
2022-03-23 20:56:04,043 train 100 8.613851e-01 70.179756 97.417114
2022-03-23 20:56:20,934 train 150 8.592758e-01 70.249207 97.435883
2022-03-23 20:56:37,827 train 200 8.567048e-01 70.326942 97.454544
2022-03-23 20:56:54,539 train 250 8.544151e-01 70.391075 97.474663
2022-03-23 20:57:11,349 train 300 8.519430e-01 70.466476 97.490524
2022-03-23 20:57:28,088 train 350 8.492827e-01 70.556656 97.509422
2022-03-23 20:57:41,580 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0942, 0.4452, 0.1199, 0.1386, 0.2021],
        [0.1480, 0.3663, 0.1560, 0.1289, 0.2007],
        [0.0736, 0.4639, 0.1221, 0.1558, 0.1845],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0862, 0.4012, 0.1783, 0.1482, 0.1860]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 20:58:04,386 train_acc  77.559998
2022-03-23 20:58:04,386 train_loss 0.646471
2022-03-23 20:58:27,049 valid_acc  75.159996
2022-03-23 20:58:27,049 valid_loss 0.713685
2022-03-23 20:58:27,049 epoch 8
2022-03-23 20:58:27,384 train 000 8.474755e-01 70.619400 97.518295
2022-03-23 20:58:44,251 train 050 8.445259e-01 70.717392 97.542603
2022-03-23 20:59:01,125 train 100 8.415669e-01 70.800720 97.564713
2022-03-23 20:59:18,109 train 150 8.390738e-01 70.882942 97.574692
2022-03-23 20:59:34,930 train 200 8.364996e-01 70.980064 97.584846
2022-03-23 20:59:51,785 train 250 8.343849e-01 71.052559 97.592384
2022-03-23 21:00:08,685 train 300 8.320938e-01 71.135254 97.602890
2022-03-23 21:00:25,603 train 350 8.298659e-01 71.217369 97.618042
2022-03-23 21:00:39,143 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0937, 0.4465, 0.1191, 0.1406, 0.2002],
        [0.1465, 0.3678, 0.1558, 0.1306, 0.1993],
        [0.0727, 0.4653, 0.1215, 0.1573, 0.1832],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0848, 0.4030, 0.1766, 0.1504, 0.1852]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:01:01,647 train_acc  77.751999
2022-03-23 21:01:01,648 train_loss 0.638669
2022-03-23 21:01:24,213 valid_acc  75.195999
2022-03-23 21:01:24,213 valid_loss 0.714478
2022-03-23 21:01:24,213 epoch 9
2022-03-23 21:01:24,564 train 000 8.281476e-01 71.280167 97.629112
2022-03-23 21:01:41,594 train 050 8.257089e-01 71.349838 97.649216
2022-03-23 21:01:58,436 train 100 8.232423e-01 71.433571 97.659683
2022-03-23 21:02:15,219 train 150 8.210214e-01 71.515442 97.673264
2022-03-23 21:02:32,053 train 200 8.184587e-01 71.593010 97.690697
2022-03-23 21:02:48,823 train 250 8.165007e-01 71.645287 97.703514
2022-03-23 21:03:05,664 train 300 8.141290e-01 71.726494 97.716408
2022-03-23 21:03:22,551 train 350 8.121867e-01 71.796707 97.730576
2022-03-23 21:03:36,109 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0938, 0.4458, 0.1204, 0.1427, 0.1972],
        [0.1464, 0.3679, 0.1568, 0.1319, 0.1970],
        [0.0725, 0.4669, 0.1215, 0.1583, 0.1809],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0842, 0.4037, 0.1754, 0.1536, 0.1830]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:03:58,657 train_acc  78.723999
2022-03-23 21:03:58,657 train_loss 0.616153
2022-03-23 21:04:21,232 valid_acc  75.743996
2022-03-23 21:04:21,232 valid_loss 0.696275
2022-03-23 21:04:21,232 epoch 10
2022-03-23 21:04:21,232 project
2022-03-23 21:04:46,818 valid_acc 75.639999
2022-03-23 21:04:46,819 valid_loss 0.705727
2022-03-23 21:05:12,485 valid_acc 17.784000
2022-03-23 21:05:12,486 valid_loss 3.352836
2022-03-23 21:05:37,850 valid_acc 70.323997
2022-03-23 21:05:37,850 valid_loss 0.858007
2022-03-23 21:06:03,355 valid_acc 67.599998
2022-03-23 21:06:03,356 valid_loss 0.933084
2022-03-23 21:06:28,752 valid_acc 60.071999
2022-03-23 21:06:28,753 valid_loss 1.184734
2022-03-23 21:06:28,753 best opid 1
2022-03-23 21:06:28,753 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0938, 0.4458, 0.1204, 0.1427, 0.1972],
        [0.1464, 0.3679, 0.1568, 0.1319, 0.1970],
        [0.0725, 0.4669, 0.1215, 0.1583, 0.1809],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:06:29,098 train 000 8.112165e-01 71.833611 97.731384
2022-03-23 21:06:45,889 train 050 8.230709e-01 71.392303 97.583939
2022-03-23 21:07:02,517 train 100 8.312644e-01 71.086006 97.511940
2022-03-23 21:07:19,211 train 150 8.375941e-01 70.845016 97.468651
2022-03-23 21:07:35,947 train 200 8.420423e-01 70.679131 97.442406
2022-03-23 21:07:52,900 train 250 8.446717e-01 70.574371 97.432945
2022-03-23 21:08:09,757 train 300 8.461136e-01 70.515923 97.431519
2022-03-23 21:08:26,619 train 350 8.466202e-01 70.499954 97.431587
2022-03-23 21:08:40,138 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1162, 0.3968, 0.1400, 0.1635, 0.1835],
        [0.1787, 0.3191, 0.1789, 0.1466, 0.1768],
        [0.0830, 0.4250, 0.1381, 0.1838, 0.1700],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:09:02,765 train_acc  70.208000
2022-03-23 21:09:02,765 train_loss 0.849502
2022-03-23 21:09:25,329 valid_acc  68.987999
2022-03-23 21:09:25,329 valid_loss 0.890532
2022-03-23 21:09:25,329 epoch 11
2022-03-23 21:09:25,662 train 000 8.466010e-01 70.498505 97.435501
2022-03-23 21:09:42,450 train 050 8.463438e-01 70.503548 97.439484
2022-03-23 21:09:59,137 train 100 8.452862e-01 70.547562 97.449402
2022-03-23 21:10:15,972 train 150 8.445754e-01 70.570213 97.458405
2022-03-23 21:10:32,730 train 200 8.435927e-01 70.608345 97.469643
2022-03-23 21:10:49,392 train 250 8.431153e-01 70.629486 97.476158
2022-03-23 21:11:06,142 train 300 8.422053e-01 70.649826 97.486267
2022-03-23 21:11:22,931 train 350 8.409652e-01 70.690575 97.494492
2022-03-23 21:11:36,334 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1269, 0.3770, 0.1459, 0.1732, 0.1770],
        [0.1927, 0.2994, 0.1875, 0.1529, 0.1675],
        [0.0884, 0.4037, 0.1457, 0.1992, 0.1632],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:11:58,840 train_acc  75.327995
2022-03-23 21:11:58,841 train_loss 0.714751
2022-03-23 21:12:21,015 valid_acc  73.287994
2022-03-23 21:12:21,015 valid_loss 0.767625
2022-03-23 21:12:21,016 epoch 12
2022-03-23 21:12:21,354 train 000 8.404121e-01 70.706917 97.499863
2022-03-23 21:12:38,041 train 050 8.392592e-01 70.745949 97.509102
2022-03-23 21:12:54,759 train 100 8.379538e-01 70.802116 97.518791
2022-03-23 21:13:11,470 train 150 8.367552e-01 70.844208 97.526680
2022-03-23 21:13:28,156 train 200 8.352154e-01 70.893745 97.541107
2022-03-23 21:13:44,835 train 250 8.341042e-01 70.929619 97.549858
2022-03-23 21:14:01,489 train 300 8.328711e-01 70.976997 97.560638
2022-03-23 21:14:18,178 train 350 8.312101e-01 71.032425 97.574303
2022-03-23 21:14:31,489 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1317, 0.3685, 0.1490, 0.1762, 0.1746],
        [0.1992, 0.2918, 0.1900, 0.1546, 0.1644],
        [0.0905, 0.3924, 0.1498, 0.2078, 0.1595],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:14:53,836 train_acc  77.084000
2022-03-23 21:14:53,837 train_loss 0.649240
2022-03-23 21:15:16,429 valid_acc  74.835999
2022-03-23 21:15:16,429 valid_loss 0.712559
2022-03-23 21:15:16,429 epoch 13
2022-03-23 21:15:16,768 train 000 8.302657e-01 71.070923 97.576477
2022-03-23 21:15:33,775 train 050 8.286855e-01 71.129333 97.586700
2022-03-23 21:15:50,712 train 100 8.274193e-01 71.170021 97.594917
2022-03-23 21:16:07,581 train 150 8.259830e-01 71.215012 97.605064
2022-03-23 21:16:24,359 train 200 8.244584e-01 71.268913 97.617683
2022-03-23 21:16:41,226 train 250 8.230169e-01 71.317993 97.626839
2022-03-23 21:16:58,116 train 300 8.213641e-01 71.374588 97.634377
2022-03-23 21:17:15,112 train 350 8.201073e-01 71.415451 97.641190
2022-03-23 21:17:28,646 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1350, 0.3621, 0.1505, 0.1802, 0.1722],
        [0.2041, 0.2868, 0.1905, 0.1566, 0.1620],
        [0.0922, 0.3845, 0.1522, 0.2145, 0.1566],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:17:51,364 train_acc  76.299995
2022-03-23 21:17:51,365 train_loss 0.698546
2022-03-23 21:18:14,025 valid_acc  73.664001
2022-03-23 21:18:14,025 valid_loss 0.775109
2022-03-23 21:18:14,026 epoch 14
2022-03-23 21:18:14,367 train 000 8.186817e-01 71.464363 97.649857
2022-03-23 21:18:31,184 train 050 8.169653e-01 71.531487 97.662933
2022-03-23 21:18:48,151 train 100 8.151681e-01 71.581978 97.674660
2022-03-23 21:19:05,030 train 150 8.136700e-01 71.637138 97.681450
2022-03-23 21:19:21,963 train 200 8.120963e-01 71.696007 97.691422
2022-03-23 21:19:38,873 train 250 8.108417e-01 71.740463 97.699036
2022-03-23 21:19:55,732 train 300 8.095008e-01 71.785767 97.705704
2022-03-23 21:20:12,611 train 350 8.080356e-01 71.836205 97.714134
2022-03-23 21:20:26,135 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1377, 0.3578, 0.1515, 0.1826, 0.1704],
        [0.2072, 0.2826, 0.1917, 0.1586, 0.1598],
        [0.0934, 0.3782, 0.1537, 0.2205, 0.1541],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:20:48,875 train_acc  77.787994
2022-03-23 21:20:48,875 train_loss 0.637712
2022-03-23 21:21:11,643 valid_acc  75.444000
2022-03-23 21:21:11,644 valid_loss 0.711039
2022-03-23 21:21:11,644 epoch 15
2022-03-23 21:21:11,644 project
2022-03-23 21:21:37,237 valid_acc 75.472000
2022-03-23 21:21:37,237 valid_loss 0.710081
2022-03-23 21:22:02,929 valid_acc 47.848000
2022-03-23 21:22:02,929 valid_loss 1.747916
2022-03-23 21:22:28,832 valid_acc 73.087997
2022-03-23 21:22:28,833 valid_loss 0.787748
2022-03-23 21:22:54,524 valid_acc 71.183998
2022-03-23 21:22:54,524 valid_loss 0.838475
2022-03-23 21:23:20,214 valid_acc 68.556000
2022-03-23 21:23:20,214 valid_loss 0.912738
2022-03-23 21:23:20,215 best opid 1
2022-03-23 21:23:20,216 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1377, 0.3578, 0.1515, 0.1826, 0.1704],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0934, 0.3782, 0.1537, 0.2205, 0.1541],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:23:20,558 train 000 8.073722e-01 71.858940 97.714523
2022-03-23 21:23:37,469 train 050 8.155669e-01 71.552139 97.616478
2022-03-23 21:23:54,312 train 100 8.216538e-01 71.331238 97.559402
2022-03-23 21:24:11,183 train 150 8.265098e-01 71.156128 97.528496
2022-03-23 21:24:28,030 train 200 8.308007e-01 70.995758 97.498863
2022-03-23 21:24:44,928 train 250 8.343617e-01 70.862312 97.475609
2022-03-23 21:25:01,849 train 300 8.372496e-01 70.752083 97.459312
2022-03-23 21:25:18,618 train 350 8.395185e-01 70.663506 97.453354
2022-03-23 21:25:32,061 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1509, 0.3217, 0.1650, 0.2007, 0.1616],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1022, 0.3426, 0.1646, 0.2423, 0.1483],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:25:54,698 train_acc  59.416000
2022-03-23 21:25:54,698 train_loss 1.140720
2022-03-23 21:26:17,356 valid_acc  58.775997
2022-03-23 21:26:17,357 valid_loss 1.156788
2022-03-23 21:26:17,357 epoch 16
2022-03-23 21:26:17,697 train 000 8.412579e-01 70.595451 97.447159
2022-03-23 21:26:34,596 train 050 8.429165e-01 70.538651 97.440880
2022-03-23 21:26:51,510 train 100 8.441239e-01 70.495049 97.438644
2022-03-23 21:27:08,435 train 150 8.452550e-01 70.450172 97.438881
2022-03-23 21:27:25,549 train 200 8.458744e-01 70.427551 97.440804
2022-03-23 21:27:42,609 train 250 8.461796e-01 70.418495 97.441498
2022-03-23 21:27:59,603 train 300 8.463984e-01 70.414345 97.442665
2022-03-23 21:28:16,672 train 350 8.461653e-01 70.423752 97.449257
2022-03-23 21:28:30,242 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1694, 0.2839, 0.1769, 0.2184, 0.1513],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1134, 0.3021, 0.1769, 0.2680, 0.1396],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:28:53,149 train_acc  72.395996
2022-03-23 21:28:53,150 train_loss 0.794123
2022-03-23 21:29:15,846 valid_acc  71.428001
2022-03-23 21:29:15,847 valid_loss 0.828096
2022-03-23 21:29:15,847 epoch 17
2022-03-23 21:29:16,190 train 000 8.458931e-01 70.437630 97.452148
2022-03-23 21:29:33,132 train 050 8.453656e-01 70.462845 97.456940
2022-03-23 21:29:50,046 train 100 8.448682e-01 70.481888 97.463280
2022-03-23 21:30:06,810 train 150 8.443662e-01 70.498131 97.470230
2022-03-23 21:30:23,563 train 200 8.436647e-01 70.523956 97.477531
2022-03-23 21:30:40,450 train 250 8.429957e-01 70.548714 97.485619
2022-03-23 21:30:57,188 train 300 8.421329e-01 70.576057 97.492706
2022-03-23 21:31:14,096 train 350 8.413091e-01 70.611046 97.496117
2022-03-23 21:31:27,605 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1822, 0.2608, 0.1824, 0.2312, 0.1433],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1215, 0.2778, 0.1850, 0.2830, 0.1327],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:31:50,104 train_acc  74.951996
2022-03-23 21:31:50,105 train_loss 0.717034
2022-03-23 21:32:12,829 valid_acc  73.223999
2022-03-23 21:32:12,829 valid_loss 0.773136
2022-03-23 21:32:12,829 epoch 18
2022-03-23 21:32:13,167 train 000 8.407742e-01 70.633286 97.501686
2022-03-23 21:32:30,036 train 050 8.398956e-01 70.667648 97.509621
2022-03-23 21:32:47,110 train 100 8.390553e-01 70.699554 97.515472
2022-03-23 21:33:04,024 train 150 8.380612e-01 70.731880 97.523186
2022-03-23 21:33:20,910 train 200 8.368677e-01 70.772629 97.533401
2022-03-23 21:33:37,856 train 250 8.358199e-01 70.806801 97.540894
2022-03-23 21:33:54,774 train 300 8.349965e-01 70.836456 97.545944
2022-03-23 21:34:11,715 train 350 8.341855e-01 70.864868 97.552612
2022-03-23 21:34:25,169 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1910, 0.2475, 0.1856, 0.2365, 0.1395],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1271, 0.2638, 0.1869, 0.2925, 0.1298],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:34:47,556 train_acc  76.231995
2022-03-23 21:34:47,557 train_loss 0.678919
2022-03-23 21:35:09,916 valid_acc  74.131996
2022-03-23 21:35:09,917 valid_loss 0.737771
2022-03-23 21:35:09,917 epoch 19
2022-03-23 21:35:10,260 train 000 8.334447e-01 70.891289 97.559280
2022-03-23 21:35:27,090 train 050 8.324335e-01 70.924637 97.567657
2022-03-23 21:35:43,961 train 100 8.313736e-01 70.964806 97.575729
2022-03-23 21:36:00,635 train 150 8.304131e-01 70.998878 97.580391
2022-03-23 21:36:17,542 train 200 8.295070e-01 71.031891 97.584984
2022-03-23 21:36:34,395 train 250 8.285742e-01 71.064865 97.590530
2022-03-23 21:36:51,323 train 300 8.275788e-01 71.100464 97.597237
2022-03-23 21:37:08,212 train 350 8.265802e-01 71.138412 97.603439
2022-03-23 21:37:21,630 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1985, 0.2344, 0.1897, 0.2426, 0.1349],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1314, 0.2495, 0.1907, 0.3029, 0.1255],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:37:44,188 train_acc  77.279999
2022-03-23 21:37:44,189 train_loss 0.654450
2022-03-23 21:38:06,902 valid_acc  74.695999
2022-03-23 21:38:06,903 valid_loss 0.719973
2022-03-23 21:38:06,903 epoch 20
2022-03-23 21:38:06,903 project
2022-03-23 21:38:32,561 valid_acc 75.540001
2022-03-23 21:38:32,561 valid_loss 0.704693
2022-03-23 21:38:58,258 valid_acc 61.783997
2022-03-23 21:38:58,259 valid_loss 1.181247
2022-03-23 21:39:23,946 valid_acc 69.435997
2022-03-23 21:39:23,946 valid_loss 0.885035
2022-03-23 21:39:49,664 valid_acc 49.091999
2022-03-23 21:39:49,664 valid_loss 1.484289
2022-03-23 21:40:15,506 valid_acc 72.799995
2022-03-23 21:40:15,507 valid_loss 0.797575
2022-03-23 21:40:15,507 best opid 3
2022-03-23 21:40:15,507 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1985, 0.2344, 0.1897, 0.2426, 0.1349],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:40:15,855 train 000 8.259217e-01 71.164085 97.606300
2022-03-23 21:40:33,027 train 050 8.292478e-01 71.076019 97.578812
2022-03-23 21:40:50,035 train 100 8.293737e-01 71.068619 97.579681
2022-03-23 21:41:07,210 train 150 8.293210e-01 71.070160 97.581940
2022-03-23 21:41:24,155 train 200 8.287987e-01 71.089600 97.586098
2022-03-23 21:41:41,315 train 250 8.282757e-01 71.107651 97.592743
2022-03-23 21:41:58,421 train 300 8.277091e-01 71.128372 97.595833
2022-03-23 21:42:15,715 train 350 8.269459e-01 71.150742 97.599258
2022-03-23 21:42:29,482 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1896, 0.2481, 0.1839, 0.2346, 0.1438],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:42:52,609 train_acc  77.239998
2022-03-23 21:42:52,610 train_loss 0.647643
2022-03-23 21:43:15,789 valid_acc  75.056000
2022-03-23 21:43:15,790 valid_loss 0.722898
2022-03-23 21:43:15,790 epoch 21
2022-03-23 21:43:16,144 train 000 8.263400e-01 71.171707 97.601440
2022-03-23 21:43:33,344 train 050 8.253472e-01 71.207581 97.607071
2022-03-23 21:43:50,513 train 100 8.243282e-01 71.248291 97.612259
2022-03-23 21:44:07,677 train 150 8.232918e-01 71.286079 97.619255
2022-03-23 21:44:24,878 train 200 8.223010e-01 71.323044 97.625237
2022-03-23 21:44:42,185 train 250 8.214618e-01 71.351082 97.632812
2022-03-23 21:44:59,385 train 300 8.203874e-01 71.394218 97.639565
2022-03-23 21:45:16,670 train 350 8.192945e-01 71.431549 97.645142
2022-03-23 21:45:30,400 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1893, 0.2480, 0.1831, 0.2350, 0.1445],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:45:53,589 train_acc  78.355995
2022-03-23 21:45:53,590 train_loss 0.638062
2022-03-23 21:46:16,938 valid_acc  75.087997
2022-03-23 21:46:16,939 valid_loss 0.720394
2022-03-23 21:46:16,939 epoch 22
2022-03-23 21:46:17,281 train 000 8.186294e-01 71.458778 97.647369
2022-03-23 21:46:34,634 train 050 8.174813e-01 71.494080 97.655914
2022-03-23 21:46:51,931 train 100 8.164437e-01 71.527542 97.663284
2022-03-23 21:47:09,163 train 150 8.151214e-01 71.573662 97.670746
2022-03-23 21:47:26,342 train 200 8.140239e-01 71.613213 97.677055
2022-03-23 21:47:43,532 train 250 8.130221e-01 71.645432 97.683296
2022-03-23 21:48:00,776 train 300 8.119185e-01 71.678871 97.690178
2022-03-23 21:48:18,142 train 350 8.106549e-01 71.725388 97.696800
2022-03-23 21:48:31,901 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1892, 0.2476, 0.1819, 0.2367, 0.1446],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:48:55,362 train_acc  80.127998
2022-03-23 21:48:55,362 train_loss 0.568115
2022-03-23 21:49:18,916 valid_acc  77.939995
2022-03-23 21:49:18,916 valid_loss 0.646707
2022-03-23 21:49:18,916 epoch 23
2022-03-23 21:49:19,266 train 000 8.097593e-01 71.760712 97.701477
2022-03-23 21:49:36,562 train 050 8.084328e-01 71.809586 97.708313
2022-03-23 21:49:53,735 train 100 8.072774e-01 71.853806 97.714561
2022-03-23 21:50:11,040 train 150 8.061204e-01 71.898735 97.719887
2022-03-23 21:50:28,272 train 200 8.049085e-01 71.939430 97.726685
2022-03-23 21:50:45,519 train 250 8.036274e-01 71.985435 97.733414
2022-03-23 21:51:02,808 train 300 8.023696e-01 72.028259 97.740906
2022-03-23 21:51:20,042 train 350 8.013851e-01 72.065933 97.746475
2022-03-23 21:51:33,791 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1888, 0.2466, 0.1808, 0.2385, 0.1453],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 0.0000, 1.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-03-23 21:51:57,114 train_acc  80.636002
2022-03-23 21:51:57,114 train_loss 0.553151
2022-03-23 21:52:20,400 valid_acc  77.715996
2022-03-23 21:52:20,401 valid_loss 0.638502
2022-03-23 21:52:20,401 epoch 24
2022-03-23 21:52:20,401 project
2022-03-23 21:52:46,619 valid_acc 77.695999
2022-03-23 21:52:46,619 valid_loss 0.640017
2022-03-23 21:53:12,935 valid_acc 58.919998
2022-03-23 21:53:12,935 valid_loss 1.312350
2022-03-23 21:53:39,194 valid_acc 76.804001
2022-03-23 21:53:39,195 valid_loss 0.675415
2022-03-23 21:54:05,230 valid_acc 74.195999
2022-03-23 21:54:05,230 valid_loss 0.749141
2022-03-23 21:54:31,128 valid_acc 71.279999
2022-03-23 21:54:31,128 valid_loss 0.834294
2022-03-23 21:54:31,128 best opid 1
2022-03-23 21:54:31,129 tensor([[0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 0., 1., 0., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward>)
2022-03-23 21:54:31,476 train 000 8.006274e-01 72.093971 97.748573
2022-03-23 21:54:48,582 train 050 8.057160e-01 71.902184 97.686249
2022-03-23 21:55:05,661 train 100 8.095904e-01 71.762711 97.651138
2022-03-23 21:55:22,687 train 150 8.126749e-01 71.650780 97.630829
2022-03-23 21:55:39,824 train 200 8.151962e-01 71.563187 97.610893
2022-03-23 21:55:56,883 train 250 8.173851e-01 71.482506 97.598785
2022-03-23 21:56:13,904 train 300 8.194401e-01 71.407829 97.587456
2022-03-23 21:56:30,920 train 350 8.209931e-01 71.357697 97.582672
2022-03-23 21:56:44,561 tensor([[0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 0., 1., 0., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward>)
2022-03-23 21:57:07,468 train_acc  63.039997
2022-03-23 21:57:07,469 train_loss 1.045467
2022-03-23 21:57:30,079 valid_acc  62.039997
2022-03-23 21:57:30,080 valid_loss 1.076304
2022-03-23 21:57:30,082 |skip_connect~0|+|skip_connect~0|skip_connect~1|+|nor_conv_3x3~0|nor_conv_1x1~1|skip_connect~2|
datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=10730
cifar10-valid  FLOP= 47.10 M, Params=0.344 MB, latency=13.56 ms.
cifar10-valid  train : [loss = 0.169, top1 = 94.47%], valid : [loss = 0.495, top1 = 85.05%]
cifar10        FLOP= 47.10 M, Params=0.344 MB, latency=14.69 ms.
cifar10        train : [loss = 0.171, top1 = 94.26%], test  : [loss = 0.377, top1 = 88.31%]
cifar100       FLOP= 47.11 M, Params=0.350 MB, latency=13.83 ms.
cifar100       train : [loss = 1.048, top1 = 69.96%], valid : [loss = 1.408, top1 = 61.33%], test : [loss = 1.398, top1 = 61.17%]
ImageNet16-120 FLOP= 11.78 M, Params=0.351 MB, latency=11.62 ms.
ImageNet16-120 train : [loss = 2.614, top1 = 34.49%], valid : [loss = 2.652, top1 = 34.43%], test : [loss = 2.698, top1 = 32.78%]
2022-03-23 21:57:30,082 cifar10 train 94.260000 test 88.310000
2022-03-23 21:57:30,082 cifar100 train 69.960000 valid 61.330000 test 61.170000
2022-03-23 21:57:30,082 imagenet16 train 34.490000 valid 34.430000 test 32.780000
