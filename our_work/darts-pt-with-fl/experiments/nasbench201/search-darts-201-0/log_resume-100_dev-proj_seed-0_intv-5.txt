2022-01-30 13:22:07,231 args = Namespace(arch_learning_rate=0.0003, arch_weight_decay=0.001, batch_size=64, ckpt_interval=20, cutout=False, cutout_length=16, cutout_prob=1.0, data='../data', dataset='cifar10', dev='proj', edge_decision='random', epochs=100, expid_tag='none', fast=False, gpu='auto', grad_clip=5, init_channels=16, layers=8, learning_rate=0.025, learning_rate_min=0.001, log_tag='', method='darts-proj', model_path='saved_models', momentum=0.9, proj_crit='acc', proj_intv=5, report_freq=50, resume_epoch=100, resume_expid='search-darts-201-0', save='../experiments/nasbench201/search-darts-201-0', search_space='nas-bench-201', seed=0, train_portion=0.5, weight_decay=0.0003)
2022-01-30 13:22:07,231 gpu device = 0
2022-01-30 13:22:33,831 param size = 1.686106MB
2022-01-30 13:22:35,410 loading checkpoint from darts-proj-201
2022-01-30 13:22:35,410 => loading checkpoint '../experiments/nasbench201/search-darts-201-0/checkpoint_100.pth.tar'
2022-01-30 13:22:35,595 => loaded checkpoint '../experiments/nasbench201/search-darts-201-0/checkpoint_100.pth.tar' (epoch 99)
2022-01-30 13:22:59,891 tensor([[0.0798, 0.7457, 0.0504, 0.0817, 0.0424],
        [0.0497, 0.8240, 0.0346, 0.0620, 0.0298],
        [0.3091, 0.4889, 0.0600, 0.0787, 0.0633],
        [0.0293, 0.7448, 0.0709, 0.1360, 0.0189],
        [0.0891, 0.6449, 0.1151, 0.1078, 0.0431],
        [0.1164, 0.7643, 0.0456, 0.0497, 0.0240]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:23:22,772 train_acc  95.671997
2022-01-30 13:23:22,773 train_loss 0.133221
2022-01-30 13:23:45,823 valid_acc  86.192001
2022-01-30 13:23:45,823 valid_loss 0.436542
2022-01-30 13:23:45,827 epoch 0
2022-01-30 13:23:45,827 project
2022-01-30 13:24:11,995 valid_acc 85.243996
2022-01-30 13:24:11,996 valid_loss 0.465746
2022-01-30 13:24:38,225 valid_acc 67.155998
2022-01-30 13:24:38,225 valid_loss 1.356525
2022-01-30 13:25:03,985 valid_acc 72.764000
2022-01-30 13:25:03,986 valid_loss 0.857652
2022-01-30 13:25:31,789 valid_acc 62.143997
2022-01-30 13:25:31,789 valid_loss 1.236250
2022-01-30 13:25:58,898 valid_acc 84.956001
2022-01-30 13:25:58,899 valid_loss 0.472040
2022-01-30 13:25:58,899 best opid 3
2022-01-30 13:25:58,899 tensor([[0.0798, 0.7457, 0.0504, 0.0817, 0.0424],
        [0.0497, 0.8240, 0.0346, 0.0620, 0.0298],
        [0.3091, 0.4889, 0.0600, 0.0787, 0.0633],
        [0.0293, 0.7448, 0.0709, 0.1360, 0.0189],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.1164, 0.7643, 0.0456, 0.0497, 0.0240]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:25:59,427 train 000 6.522666e+00 7.812500 53.125000
2022-01-30 13:26:16,265 train 050 2.938205e+00 21.629902 74.877457
2022-01-30 13:26:33,262 train 100 2.351848e+00 28.418936 81.250000
2022-01-30 13:26:50,208 train 150 2.096345e+00 33.050495 84.219788
2022-01-30 13:27:07,117 train 200 1.945954e+00 36.108521 86.108521
2022-01-30 13:27:24,049 train 250 1.840018e+00 38.738796 87.618279
2022-01-30 13:27:41,112 train 300 1.760686e+00 40.915695 88.610878
2022-01-30 13:27:58,061 train 350 1.691687e+00 42.926460 89.480949
2022-01-30 13:28:11,665 tensor([[0.0803, 0.7468, 0.0506, 0.0812, 0.0410],
        [0.0502, 0.8236, 0.0348, 0.0625, 0.0290],
        [0.3107, 0.4889, 0.0604, 0.0790, 0.0610],
        [0.0298, 0.7426, 0.0715, 0.1374, 0.0187],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.1171, 0.7632, 0.0462, 0.0503, 0.0233]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:28:34,125 train_acc  55.995998
2022-01-30 13:28:34,125 train_loss 1.218321
2022-01-30 13:28:56,166 valid_acc  55.183998
2022-01-30 13:28:56,167 valid_loss 1.244097
2022-01-30 13:28:56,167 epoch 1
2022-01-30 13:28:56,553 train 000 1.639764e+00 44.565914 90.129272
2022-01-30 13:29:14,746 train 050 1.583217e+00 46.341637 90.779793
2022-01-30 13:29:33,277 train 100 1.535128e+00 47.727562 91.380623
2022-01-30 13:29:51,904 train 150 1.489016e+00 49.198017 91.887840
2022-01-30 13:30:08,795 train 200 1.447911e+00 50.483311 92.319885
2022-01-30 13:30:26,000 train 250 1.407674e+00 51.906776 92.711372
2022-01-30 13:30:42,904 train 300 1.369854e+00 53.133472 93.064346
2022-01-30 13:30:59,834 train 350 1.337980e+00 54.211613 93.361282
2022-01-30 13:31:13,370 tensor([[0.0831, 0.7391, 0.0523, 0.0846, 0.0408],
        [0.0520, 0.8188, 0.0356, 0.0638, 0.0298],
        [0.3180, 0.4812, 0.0608, 0.0794, 0.0606],
        [0.0309, 0.7351, 0.0734, 0.1413, 0.0193],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.1212, 0.7555, 0.0477, 0.0517, 0.0239]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:31:36,015 train_acc  69.624001
2022-01-30 13:31:36,016 train_loss 0.871916
2022-01-30 13:31:58,766 valid_acc  68.743996
2022-01-30 13:31:58,767 valid_loss 0.906039
2022-01-30 13:31:58,767 epoch 2
2022-01-30 13:31:59,111 train 000 1.312181e+00 55.021576 93.606186
2022-01-30 13:32:16,038 train 050 1.279281e+00 56.169270 93.877663
2022-01-30 13:32:33,016 train 100 1.251593e+00 57.101868 94.127228
2022-01-30 13:32:49,772 train 150 1.226644e+00 57.939457 94.333260
2022-01-30 13:33:07,138 train 200 1.203101e+00 58.774494 94.513550
2022-01-30 13:33:25,718 train 250 1.178169e+00 59.610378 94.726326
2022-01-30 13:33:44,230 train 300 1.154637e+00 60.392124 94.916550
2022-01-30 13:34:01,841 train 350 1.134143e+00 61.108963 95.078934
2022-01-30 13:34:15,433 tensor([[0.0853, 0.7324, 0.0542, 0.0879, 0.0402],
        [0.0530, 0.8153, 0.0362, 0.0649, 0.0305],
        [0.3211, 0.4777, 0.0610, 0.0798, 0.0604],
        [0.0316, 0.7294, 0.0747, 0.1444, 0.0199],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.1231, 0.7510, 0.0487, 0.0529, 0.0243]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:34:38,191 train_acc  79.507996
2022-01-30 13:34:38,192 train_loss 0.588927
2022-01-30 13:35:01,045 valid_acc  77.019997
2022-01-30 13:35:01,046 valid_loss 0.661909
2022-01-30 13:35:01,046 epoch 3
2022-01-30 13:35:01,388 train 000 1.116861e+00 61.718002 95.200096
2022-01-30 13:35:18,318 train 050 1.097643e+00 62.342838 95.350349
2022-01-30 13:35:35,160 train 100 1.077590e+00 63.020473 95.477760
2022-01-30 13:35:52,115 train 150 1.059404e+00 63.633896 95.608521
2022-01-30 13:36:09,015 train 200 1.042666e+00 64.176453 95.732040
2022-01-30 13:36:25,912 train 250 1.026700e+00 64.727005 95.842484
2022-01-30 13:36:42,764 train 300 1.012193e+00 65.177582 95.946487
2022-01-30 13:36:59,332 train 350 9.975848e-01 65.695030 96.051880
2022-01-30 13:37:14,154 tensor([[0.0875, 0.7269, 0.0554, 0.0910, 0.0392],
        [0.0544, 0.8112, 0.0371, 0.0666, 0.0307],
        [0.3247, 0.4741, 0.0617, 0.0802, 0.0593],
        [0.0324, 0.7237, 0.0763, 0.1474, 0.0202],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.1253, 0.7467, 0.0496, 0.0542, 0.0243]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:37:38,752 train_acc  81.867996
2022-01-30 13:37:38,753 train_loss 0.517749
2022-01-30 13:38:02,409 valid_acc  78.683998
2022-01-30 13:38:02,410 valid_loss 0.616301
2022-01-30 13:38:02,410 epoch 4
2022-01-30 13:38:02,733 train 000 9.865487e-01 66.039734 96.128479
2022-01-30 13:38:19,725 train 050 9.722720e-01 66.513985 96.229080
2022-01-30 13:38:36,718 train 100 9.592414e-01 66.960663 96.321762
2022-01-30 13:38:53,708 train 150 9.459911e-01 67.414101 96.409035
2022-01-30 13:39:10,693 train 200 9.337181e-01 67.832970 96.495781
2022-01-30 13:39:27,649 train 250 9.219185e-01 68.222702 96.576027
2022-01-30 13:39:44,593 train 300 9.109623e-01 68.589851 96.647774
2022-01-30 13:40:01,536 train 350 9.005098e-01 68.936180 96.719856
2022-01-30 13:40:15,179 tensor([[0.0886, 0.7220, 0.0566, 0.0944, 0.0383],
        [0.0543, 0.8110, 0.0372, 0.0669, 0.0306],
        [0.3230, 0.4759, 0.0617, 0.0807, 0.0587],
        [0.0324, 0.7228, 0.0762, 0.1483, 0.0204],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.1243, 0.7482, 0.0494, 0.0541, 0.0241]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:40:37,890 train_acc  84.311996
2022-01-30 13:40:37,891 train_loss 0.448787
2022-01-30 13:41:00,307 valid_acc  80.931999
2022-01-30 13:41:00,307 valid_loss 0.559623
2022-01-30 13:41:00,307 epoch 5
2022-01-30 13:41:00,307 project
2022-01-30 13:41:28,181 valid_acc 80.795998
2022-01-30 13:41:28,181 valid_loss 0.563900
2022-01-30 13:41:55,660 valid_acc 8.696000
2022-01-30 13:41:55,661 valid_loss 7.578815
2022-01-30 13:42:20,889 valid_acc 77.087997
2022-01-30 13:42:20,890 valid_loss 0.668546
2022-01-30 13:42:46,416 valid_acc 67.680000
2022-01-30 13:42:46,417 valid_loss 0.977163
2022-01-30 13:43:11,869 valid_acc 80.939995
2022-01-30 13:43:11,869 valid_loss 0.564101
2022-01-30 13:43:11,869 best opid 1
2022-01-30 13:43:11,870 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0543, 0.8110, 0.0372, 0.0669, 0.0306],
        [0.3230, 0.4759, 0.0617, 0.0807, 0.0587],
        [0.0324, 0.7228, 0.0762, 0.1483, 0.0204],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.1243, 0.7482, 0.0494, 0.0541, 0.0241]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:43:12,212 train 000 8.923166e-01 69.208565 96.771255
2022-01-30 13:43:29,144 train 050 8.918623e-01 69.205696 96.785530
2022-01-30 13:43:46,082 train 100 8.853967e-01 69.432701 96.841721
2022-01-30 13:44:02,987 train 150 8.800725e-01 69.611778 96.884842
2022-01-30 13:44:19,872 train 200 8.739083e-01 69.826065 96.936836
2022-01-30 13:44:36,818 train 250 8.685817e-01 70.006523 96.977257
2022-01-30 13:44:53,316 train 300 8.624790e-01 70.215714 97.017273
2022-01-30 13:45:11,726 train 350 8.572016e-01 70.399559 97.058266
2022-01-30 13:45:26,548 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0588, 0.7974, 0.0398, 0.0722, 0.0318],
        [0.3438, 0.4524, 0.0640, 0.0836, 0.0562],
        [0.0349, 0.7054, 0.0807, 0.1579, 0.0210],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.1343, 0.7293, 0.0534, 0.0584, 0.0246]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:45:51,082 train_acc  81.059998
2022-01-30 13:45:51,083 train_loss 0.541423
2022-01-30 13:46:13,486 valid_acc  78.267998
2022-01-30 13:46:13,486 valid_loss 0.634330
2022-01-30 13:46:13,486 epoch 6
2022-01-30 13:46:13,826 train 000 8.520585e-01 70.581886 97.093910
2022-01-30 13:46:30,717 train 050 8.454114e-01 70.802017 97.138924
2022-01-30 13:46:47,647 train 100 8.394003e-01 71.023369 97.176346
2022-01-30 13:47:04,529 train 150 8.328330e-01 71.246490 97.218529
2022-01-30 13:47:21,417 train 200 8.271752e-01 71.433838 97.255997
2022-01-30 13:47:38,270 train 250 8.216962e-01 71.629616 97.290207
2022-01-30 13:47:55,104 train 300 8.164862e-01 71.815620 97.322525
2022-01-30 13:48:11,913 train 350 8.108326e-01 71.999374 97.358292
2022-01-30 13:48:25,410 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0604, 0.7919, 0.0408, 0.0747, 0.0323],
        [0.3488, 0.4466, 0.0642, 0.0853, 0.0551],
        [0.0357, 0.6996, 0.0817, 0.1615, 0.0214],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.1369, 0.7241, 0.0546, 0.0597, 0.0246]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:48:47,635 train_acc  82.115997
2022-01-30 13:48:47,636 train_loss 0.508865
2022-01-30 13:49:11,248 valid_acc  79.175995
2022-01-30 13:49:11,249 valid_loss 0.615836
2022-01-30 13:49:11,249 epoch 7
2022-01-30 13:49:11,616 train 000 8.068982e-01 72.137619 97.382095
2022-01-30 13:49:30,105 train 050 8.015495e-01 72.313530 97.412819
2022-01-30 13:49:48,511 train 100 7.960988e-01 72.499229 97.444122
2022-01-30 13:50:05,354 train 150 7.916098e-01 72.660614 97.472710
2022-01-30 13:50:22,477 train 200 7.864104e-01 72.842590 97.505112
2022-01-30 13:50:39,311 train 250 7.816336e-01 73.007996 97.534332
2022-01-30 13:50:56,120 train 300 7.766370e-01 73.175674 97.562592
2022-01-30 13:51:12,920 train 350 7.716363e-01 73.341469 97.594498
2022-01-30 13:51:26,422 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0611, 0.7890, 0.0413, 0.0761, 0.0325],
        [0.3503, 0.4451, 0.0645, 0.0857, 0.0544],
        [0.0362, 0.6949, 0.0825, 0.1647, 0.0217],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.1376, 0.7219, 0.0551, 0.0607, 0.0246]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:51:48,967 train_acc  84.607994
2022-01-30 13:51:48,967 train_loss 0.438449
2022-01-30 13:52:11,468 valid_acc  80.916000
2022-01-30 13:52:11,469 valid_loss 0.567225
2022-01-30 13:52:11,469 epoch 8
2022-01-30 13:52:11,815 train 000 7.679785e-01 73.458496 97.615265
2022-01-30 13:52:28,857 train 050 7.632833e-01 73.621986 97.643944
2022-01-30 13:52:45,737 train 100 7.584418e-01 73.786713 97.671753
2022-01-30 13:53:03,465 train 150 7.539317e-01 73.946411 97.696793
2022-01-30 13:53:21,931 train 200 7.492866e-01 74.107880 97.722961
2022-01-30 13:53:40,362 train 250 7.453455e-01 74.239120 97.746971
2022-01-30 13:53:57,942 train 300 7.410194e-01 74.382019 97.770264
2022-01-30 13:54:14,941 train 350 7.375394e-01 74.501495 97.792900
2022-01-30 13:54:28,468 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0610, 0.7893, 0.0414, 0.0761, 0.0322],
        [0.3492, 0.4477, 0.0643, 0.0852, 0.0537],
        [0.0362, 0.6957, 0.0816, 0.1646, 0.0218],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.1369, 0.7226, 0.0552, 0.0610, 0.0243]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:54:51,086 train_acc  85.615997
2022-01-30 13:54:51,086 train_loss 0.412578
2022-01-30 13:55:13,685 valid_acc  81.299995
2022-01-30 13:55:13,686 valid_loss 0.548403
2022-01-30 13:55:13,686 epoch 9
2022-01-30 13:55:14,022 train 000 7.344404e-01 74.612549 97.809509
2022-01-30 13:55:30,900 train 050 7.302607e-01 74.753357 97.834961
2022-01-30 13:55:47,779 train 100 7.264111e-01 74.892426 97.856255
2022-01-30 13:56:04,746 train 150 7.225367e-01 75.025139 97.878670
2022-01-30 13:56:21,601 train 200 7.185267e-01 75.160172 97.898376
2022-01-30 13:56:38,472 train 250 7.151709e-01 75.273369 97.914658
2022-01-30 13:56:55,050 train 300 7.113744e-01 75.406532 97.933792
2022-01-30 13:57:13,470 train 350 7.079310e-01 75.521286 97.953239
2022-01-30 13:57:28,200 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0608, 0.7898, 0.0412, 0.0762, 0.0320],
        [0.3472, 0.4504, 0.0641, 0.0852, 0.0531],
        [0.0362, 0.6965, 0.0809, 0.1645, 0.0220],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.1358, 0.7241, 0.0549, 0.0610, 0.0241]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 13:57:52,471 train_acc  85.811996
2022-01-30 13:57:52,471 train_loss 0.395630
2022-01-30 13:58:14,852 valid_acc  81.883995
2022-01-30 13:58:14,852 valid_loss 0.538964
2022-01-30 13:58:14,853 epoch 10
2022-01-30 13:58:14,853 project
2022-01-30 13:58:40,289 valid_acc 80.984001
2022-01-30 13:58:40,289 valid_loss 0.562205
2022-01-30 13:59:05,741 valid_acc 10.415999
2022-01-30 13:59:05,741 valid_loss 7.553914
2022-01-30 13:59:31,138 valid_acc 80.743996
2022-01-30 13:59:31,138 valid_loss 0.568810
2022-01-30 13:59:56,629 valid_acc 79.827995
2022-01-30 13:59:56,630 valid_loss 0.591170
2022-01-30 14:00:22,139 valid_acc 80.947998
2022-01-30 14:00:22,139 valid_loss 0.569428
2022-01-30 14:00:22,140 best opid 1
2022-01-30 14:00:22,140 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0608, 0.7898, 0.0412, 0.0762, 0.0320],
        [0.3472, 0.4504, 0.0641, 0.0852, 0.0531],
        [0.0362, 0.6965, 0.0809, 0.1645, 0.0220],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:00:22,482 train 000 7.053697e-01 75.601051 97.971321
2022-01-30 14:00:39,494 train 050 7.077729e-01 75.523170 97.962204
2022-01-30 14:00:56,364 train 100 7.060318e-01 75.595016 97.975937
2022-01-30 14:01:14,837 train 150 7.039726e-01 75.657776 97.993179
2022-01-30 14:01:33,249 train 200 7.017969e-01 75.728134 98.009995
2022-01-30 14:01:51,375 train 250 6.993818e-01 75.813713 98.021904
2022-01-30 14:02:08,317 train 300 6.968121e-01 75.898743 98.039467
2022-01-30 14:02:25,176 train 350 6.946385e-01 75.977379 98.052956
2022-01-30 14:02:38,652 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0726, 0.7551, 0.0478, 0.0883, 0.0363],
        [0.3873, 0.4029, 0.0691, 0.0909, 0.0499],
        [0.0415, 0.6574, 0.0906, 0.1867, 0.0238],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:03:01,145 train_acc  84.820000
2022-01-30 14:03:01,145 train_loss 0.442803
2022-01-30 14:03:23,692 valid_acc  80.911995
2022-01-30 14:03:23,693 valid_loss 0.563404
2022-01-30 14:03:23,693 epoch 11
2022-01-30 14:03:24,042 train 000 6.928312e-01 76.037941 98.062996
2022-01-30 14:03:40,933 train 050 6.902680e-01 76.129143 98.077728
2022-01-30 14:03:57,767 train 100 6.874376e-01 76.229637 98.092468
2022-01-30 14:04:14,614 train 150 6.849092e-01 76.313126 98.105484
2022-01-30 14:04:31,481 train 200 6.826398e-01 76.388161 98.118904
2022-01-30 14:04:47,862 train 250 6.805826e-01 76.458443 98.133743
2022-01-30 14:05:06,067 train 300 6.781890e-01 76.541130 98.147583
2022-01-30 14:05:24,501 train 350 6.758028e-01 76.615997 98.162132
2022-01-30 14:05:39,260 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0754, 0.7480, 0.0486, 0.0909, 0.0370],
        [0.3968, 0.3940, 0.0691, 0.0911, 0.0490],
        [0.0429, 0.6443, 0.0940, 0.1944, 0.0243],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:06:02,042 train_acc  82.975998
2022-01-30 14:06:02,043 train_loss 0.480320
2022-01-30 14:06:24,630 valid_acc  79.075996
2022-01-30 14:06:24,630 valid_loss 0.615297
2022-01-30 14:06:24,630 epoch 12
2022-01-30 14:06:24,974 train 000 6.741505e-01 76.684975 98.171722
2022-01-30 14:06:41,902 train 050 6.716619e-01 76.770401 98.186729
2022-01-30 14:06:58,739 train 100 6.693620e-01 76.850464 98.201744
2022-01-30 14:07:15,622 train 150 6.673319e-01 76.926285 98.213547
2022-01-30 14:07:32,488 train 200 6.649852e-01 77.000870 98.226387
2022-01-30 14:07:49,357 train 250 6.630280e-01 77.068886 98.236748
2022-01-30 14:08:06,318 train 300 6.608059e-01 77.136475 98.250664
2022-01-30 14:08:23,159 train 350 6.587900e-01 77.200867 98.266167
2022-01-30 14:08:36,572 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0767, 0.7456, 0.0487, 0.0913, 0.0377],
        [0.4014, 0.3905, 0.0690, 0.0902, 0.0489],
        [0.0438, 0.6386, 0.0945, 0.1982, 0.0250],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:08:59,449 train_acc  85.715996
2022-01-30 14:08:59,450 train_loss 0.415101
2022-01-30 14:09:23,998 valid_acc  81.136002
2022-01-30 14:09:23,998 valid_loss 0.558871
2022-01-30 14:09:23,999 epoch 13
2022-01-30 14:09:24,374 train 000 6.572463e-01 77.252167 98.271721
2022-01-30 14:09:42,872 train 050 6.549067e-01 77.331963 98.284004
2022-01-30 14:09:59,642 train 100 6.527660e-01 77.406296 98.295746
2022-01-30 14:10:16,699 train 150 6.505509e-01 77.482491 98.308151
2022-01-30 14:10:33,531 train 200 6.485555e-01 77.546295 98.320923
2022-01-30 14:10:50,441 train 250 6.466199e-01 77.617981 98.331398
2022-01-30 14:11:07,583 train 300 6.446450e-01 77.681953 98.341972
2022-01-30 14:11:24,603 train 350 6.429055e-01 77.743881 98.349754
2022-01-30 14:11:38,305 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0788, 0.7404, 0.0495, 0.0931, 0.0382],
        [0.4083, 0.3843, 0.0693, 0.0899, 0.0482],
        [0.0450, 0.6311, 0.0967, 0.2017, 0.0256],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:12:01,481 train_acc  85.759995
2022-01-30 14:12:01,482 train_loss 0.415208
2022-01-30 14:12:24,405 valid_acc  80.844002
2022-01-30 14:12:24,406 valid_loss 0.554944
2022-01-30 14:12:24,406 epoch 14
2022-01-30 14:12:24,752 train 000 6.412064e-01 77.797203 98.359726
2022-01-30 14:12:41,715 train 050 6.392748e-01 77.864708 98.370056
2022-01-30 14:12:59,305 train 100 6.371603e-01 77.932411 98.381325
2022-01-30 14:13:17,806 train 150 6.351057e-01 78.001968 98.388496
2022-01-30 14:13:36,164 train 200 6.332434e-01 78.062859 98.398849
2022-01-30 14:13:53,736 train 250 6.317905e-01 78.109291 98.405472
2022-01-30 14:14:10,774 train 300 6.299726e-01 78.173882 98.414680
2022-01-30 14:14:27,699 train 350 6.281964e-01 78.231720 98.422661
2022-01-30 14:14:41,260 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0799, 0.7389, 0.0495, 0.0937, 0.0379],
        [0.4128, 0.3815, 0.0690, 0.0893, 0.0474],
        [0.0458, 0.6284, 0.0960, 0.2040, 0.0258],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:15:04,088 train_acc  87.307999
2022-01-30 14:15:04,089 train_loss 0.365837
2022-01-30 14:15:26,894 valid_acc  82.692001
2022-01-30 14:15:26,895 valid_loss 0.515484
2022-01-30 14:15:26,895 epoch 15
2022-01-30 14:15:26,895 project
2022-01-30 14:15:52,514 valid_acc 82.075996
2022-01-30 14:15:52,515 valid_loss 0.529450
2022-01-30 14:16:18,258 valid_acc 41.576000
2022-01-30 14:16:18,259 valid_loss 2.580398
2022-01-30 14:16:44,056 valid_acc 81.119995
2022-01-30 14:16:44,057 valid_loss 0.555862
2022-01-30 14:17:11,191 valid_acc 80.255997
2022-01-30 14:17:11,191 valid_loss 0.585922
2022-01-30 14:17:38,775 valid_acc 81.848000
2022-01-30 14:17:38,776 valid_loss 0.539144
2022-01-30 14:17:38,776 best opid 1
2022-01-30 14:17:38,777 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0799, 0.7389, 0.0495, 0.0937, 0.0379],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0458, 0.6284, 0.0960, 0.2040, 0.0258],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:17:39,156 train 000 6.270800e-01 78.265312 98.425873
2022-01-30 14:17:56,506 train 050 6.363733e-01 77.912514 98.331055
2022-01-30 14:18:13,610 train 100 6.430445e-01 77.666046 98.284500
2022-01-30 14:18:30,743 train 150 6.478612e-01 77.487625 98.257179
2022-01-30 14:18:47,698 train 200 6.512995e-01 77.376091 98.244232
2022-01-30 14:19:04,667 train 250 6.536503e-01 77.299110 98.237633
2022-01-30 14:19:21,649 train 300 6.549002e-01 77.256104 98.237724
2022-01-30 14:19:38,635 train 350 6.552254e-01 77.250267 98.242607
2022-01-30 14:19:52,252 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1024, 0.6744, 0.0616, 0.1173, 0.0443],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0560, 0.5601, 0.1133, 0.2425, 0.0281],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:20:14,973 train_acc  78.063995
2022-01-30 14:20:14,974 train_loss 0.653650
2022-01-30 14:20:37,669 valid_acc  75.603996
2022-01-30 14:20:37,670 valid_loss 0.718815
2022-01-30 14:20:37,670 epoch 16
2022-01-30 14:20:38,010 train 000 6.554984e-01 77.244637 98.242775
2022-01-30 14:20:54,830 train 050 6.551965e-01 77.261047 98.246056
2022-01-30 14:21:13,299 train 100 6.548556e-01 77.272530 98.251511
2022-01-30 14:21:31,829 train 150 6.544129e-01 77.288460 98.258087
2022-01-30 14:21:50,258 train 200 6.536440e-01 77.315536 98.266258
2022-01-30 14:22:07,017 train 250 6.528276e-01 77.348198 98.273102
2022-01-30 14:22:24,136 train 300 6.522112e-01 77.372971 98.276985
2022-01-30 14:22:41,250 train 350 6.512756e-01 77.404465 98.285301
2022-01-30 14:22:54,841 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1177, 0.6360, 0.0687, 0.1303, 0.0473],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0630, 0.5244, 0.1222, 0.2611, 0.0292],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:23:17,612 train_acc  82.820000
2022-01-30 14:23:17,613 train_loss 0.501540
2022-01-30 14:23:40,290 valid_acc  79.416000
2022-01-30 14:23:40,291 valid_loss 0.603242
2022-01-30 14:23:40,291 epoch 17
2022-01-30 14:23:40,632 train 000 6.505896e-01 77.424110 98.289436
2022-01-30 14:23:57,602 train 050 6.494519e-01 77.468102 98.296143
2022-01-30 14:24:14,584 train 100 6.486197e-01 77.495224 98.303909
2022-01-30 14:24:31,617 train 150 6.476563e-01 77.530922 98.310417
2022-01-30 14:24:48,352 train 200 6.466957e-01 77.567467 98.316605
2022-01-30 14:25:06,079 train 250 6.458442e-01 77.595764 98.324051
2022-01-30 14:25:24,532 train 300 6.448265e-01 77.627495 98.330948
2022-01-30 14:25:42,862 train 350 6.438100e-01 77.663231 98.337524
2022-01-30 14:25:57,270 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1288, 0.6132, 0.0721, 0.1369, 0.0490],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0680, 0.5027, 0.1255, 0.2738, 0.0299],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:26:19,689 train_acc  83.456001
2022-01-30 14:26:19,690 train_loss 0.480599
2022-01-30 14:26:42,420 valid_acc  79.395996
2022-01-30 14:26:42,421 valid_loss 0.597136
2022-01-30 14:26:42,421 epoch 18
2022-01-30 14:26:42,757 train 000 6.430476e-01 77.690063 98.344238
2022-01-30 14:26:59,683 train 050 6.418439e-01 77.731964 98.350189
2022-01-30 14:27:16,640 train 100 6.409029e-01 77.764954 98.355621
2022-01-30 14:27:33,586 train 150 6.398906e-01 77.797256 98.362274
2022-01-30 14:27:50,551 train 200 6.388258e-01 77.834747 98.367989
2022-01-30 14:28:07,544 train 250 6.376501e-01 77.877502 98.375542
2022-01-30 14:28:24,483 train 300 6.367927e-01 77.905609 98.381294
2022-01-30 14:28:41,387 train 350 6.360282e-01 77.931648 98.386963
2022-01-30 14:28:54,559 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1394, 0.5943, 0.0751, 0.1413, 0.0499],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0724, 0.4829, 0.1286, 0.2859, 0.0302],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:29:18,742 train_acc  84.107994
2022-01-30 14:29:18,743 train_loss 0.460851
2022-01-30 14:29:43,126 valid_acc  80.463997
2022-01-30 14:29:43,127 valid_loss 0.572274
2022-01-30 14:29:43,127 epoch 19
2022-01-30 14:29:43,498 train 000 6.352171e-01 77.957497 98.392853
2022-01-30 14:30:01,489 train 050 6.341125e-01 77.992905 98.400459
2022-01-30 14:30:18,396 train 100 6.330532e-01 78.030548 98.406319
2022-01-30 14:30:35,362 train 150 6.319722e-01 78.068520 98.412720
2022-01-30 14:30:52,411 train 200 6.310905e-01 78.100662 98.417389
2022-01-30 14:31:09,424 train 250 6.299885e-01 78.141335 98.425453
2022-01-30 14:31:26,453 train 300 6.290025e-01 78.177254 98.431000
2022-01-30 14:31:43,529 train 350 6.279653e-01 78.212288 98.435265
2022-01-30 14:31:57,243 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1472, 0.5832, 0.0762, 0.1433, 0.0502],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0755, 0.4697, 0.1301, 0.2945, 0.0302],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:32:19,998 train_acc  84.687996
2022-01-30 14:32:19,998 train_loss 0.439324
2022-01-30 14:32:42,559 valid_acc  80.907997
2022-01-30 14:32:42,559 valid_loss 0.555809
2022-01-30 14:32:42,559 epoch 20
2022-01-30 14:32:42,559 project
2022-01-30 14:33:08,004 valid_acc 80.599998
2022-01-30 14:33:08,005 valid_loss 0.562977
2022-01-30 14:33:35,587 valid_acc 39.703999
2022-01-30 14:33:35,588 valid_loss 2.670933
2022-01-30 14:34:02,688 valid_acc 76.523994
2022-01-30 14:34:02,689 valid_loss 0.683768
2022-01-30 14:34:27,826 valid_acc 44.107998
2022-01-30 14:34:27,826 valid_loss 1.718571
2022-01-30 14:34:53,168 valid_acc 80.987999
2022-01-30 14:34:53,168 valid_loss 0.558493
2022-01-30 14:34:53,169 best opid 1
2022-01-30 14:34:53,169 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1472, 0.5832, 0.0762, 0.1433, 0.0502],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:34:53,514 train 000 6.273277e-01 78.237785 98.436798
2022-01-30 14:35:10,390 train 050 6.352453e-01 77.929283 98.344215
2022-01-30 14:35:27,251 train 100 6.417471e-01 77.678764 98.285759
2022-01-30 14:35:44,093 train 150 6.478797e-01 77.435921 98.238647
2022-01-30 14:36:00,925 train 200 6.534037e-01 77.225540 98.198929
2022-01-30 14:36:17,740 train 250 6.588290e-01 77.022812 98.163597
2022-01-30 14:36:34,657 train 300 6.637235e-01 76.844154 98.130821
2022-01-30 14:36:51,417 train 350 6.684037e-01 76.668251 98.100159
2022-01-30 14:37:04,728 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1570, 0.5591, 0.0803, 0.1529, 0.0507],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:37:29,158 train_acc  43.743999
2022-01-30 14:37:29,159 train_loss 1.576428
2022-01-30 14:37:53,568 valid_acc  43.320000
2022-01-30 14:37:53,569 valid_loss 1.591808
2022-01-30 14:37:53,569 epoch 21
2022-01-30 14:37:53,938 train 000 6.719859e-01 76.533913 98.075096
2022-01-30 14:38:10,859 train 050 6.764082e-01 76.372421 98.045677
2022-01-30 14:38:27,963 train 100 6.804435e-01 76.225861 98.021690
2022-01-30 14:38:44,884 train 150 6.843244e-01 76.077126 98.001549
2022-01-30 14:39:01,730 train 200 6.878846e-01 75.953026 97.978294
2022-01-30 14:39:18,634 train 250 6.914116e-01 75.820610 97.961609
2022-01-30 14:39:35,583 train 300 6.947318e-01 75.692131 97.945305
2022-01-30 14:39:52,422 train 350 6.977811e-01 75.581047 97.927902
2022-01-30 14:40:05,925 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1721, 0.5206, 0.0871, 0.1702, 0.0500],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:40:28,532 train_acc  57.396000
2022-01-30 14:40:28,533 train_loss 1.216051
2022-01-30 14:40:50,955 valid_acc  57.379997
2022-01-30 14:40:50,956 valid_loss 1.231394
2022-01-30 14:40:50,956 epoch 22
2022-01-30 14:40:51,287 train 000 7.002499e-01 75.488853 97.914246
2022-01-30 14:41:08,224 train 050 7.028435e-01 75.394211 97.902084
2022-01-30 14:41:26,714 train 100 7.053345e-01 75.307121 97.889175
2022-01-30 14:41:45,045 train 150 7.075372e-01 75.229958 97.878906
2022-01-30 14:42:03,002 train 200 7.097392e-01 75.146927 97.870178
2022-01-30 14:42:19,749 train 250 7.117457e-01 75.077377 97.862961
2022-01-30 14:42:36,634 train 300 7.136645e-01 75.007553 97.854950
2022-01-30 14:42:53,540 train 350 7.152349e-01 74.952660 97.851219
2022-01-30 14:43:07,162 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.1940, 0.4712, 0.0959, 0.1893, 0.0495],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:43:29,860 train_acc  66.591995
2022-01-30 14:43:29,861 train_loss 0.943358
2022-01-30 14:43:52,466 valid_acc  66.220001
2022-01-30 14:43:52,466 valid_loss 0.968652
2022-01-30 14:43:52,467 epoch 23
2022-01-30 14:43:52,809 train 000 7.163014e-01 74.919144 97.847893
2022-01-30 14:44:09,849 train 050 7.174979e-01 74.880676 97.844063
2022-01-30 14:44:26,795 train 100 7.187254e-01 74.842293 97.841484
2022-01-30 14:44:43,755 train 150 7.198064e-01 74.809296 97.840645
2022-01-30 14:45:00,367 train 200 7.206637e-01 74.784813 97.838448
2022-01-30 14:45:18,468 train 250 7.211224e-01 74.771095 97.839828
2022-01-30 14:45:36,900 train 300 7.216886e-01 74.756676 97.839684
2022-01-30 14:45:55,307 train 350 7.221447e-01 74.745094 97.841042
2022-01-30 14:46:09,133 tensor([[0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.2239, 0.4198, 0.1043, 0.2041, 0.0479],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000, 1.0000, 0.0000],
        [0.0000, 1.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',
       grad_fn=<SoftmaxBackward>)
2022-01-30 14:46:31,757 train_acc  73.723999
2022-01-30 14:46:31,757 train_loss 0.757976
2022-01-30 14:46:54,518 valid_acc  71.484001
2022-01-30 14:46:54,518 valid_loss 0.817408
2022-01-30 14:46:54,518 epoch 24
2022-01-30 14:46:54,518 project
2022-01-30 14:47:20,260 valid_acc 73.351997
2022-01-30 14:47:20,260 valid_loss 0.782733
2022-01-30 14:47:45,846 valid_acc 60.792000
2022-01-30 14:47:45,847 valid_loss 1.288674
2022-01-30 14:48:11,402 valid_acc 67.203995
2022-01-30 14:48:11,402 valid_loss 0.948583
2022-01-30 14:48:37,101 valid_acc 47.779999
2022-01-30 14:48:37,101 valid_loss 1.468218
2022-01-30 14:49:02,219 valid_acc 73.928001
2022-01-30 14:49:02,219 valid_loss 0.775792
2022-01-30 14:49:02,219 best opid 3
2022-01-30 14:49:02,220 tensor([[0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward>)
2022-01-30 14:49:02,547 train 000 7.225314e-01 74.741524 97.840393
2022-01-30 14:49:20,744 train 050 7.290966e-01 74.552437 97.775269
2022-01-30 14:49:39,126 train 100 7.310439e-01 74.482414 97.765083
2022-01-30 14:49:57,452 train 150 7.320592e-01 74.447891 97.764183
2022-01-30 14:50:14,312 train 200 7.324461e-01 74.438705 97.763618
2022-01-30 14:50:31,348 train 250 7.326497e-01 74.431709 97.767113
2022-01-30 14:50:48,306 train 300 7.328172e-01 74.425766 97.769768
2022-01-30 14:51:05,151 train 350 7.329218e-01 74.424866 97.772400
2022-01-30 14:51:18,693 tensor([[0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0.],
        [0., 0., 0., 1., 0.],
        [0., 1., 0., 0., 0.]], device='cuda:0', grad_fn=<SoftmaxBackward>)
2022-01-30 14:51:41,478 train_acc  76.515999
2022-01-30 14:51:41,478 train_loss 0.684056
2022-01-30 14:52:04,071 valid_acc  74.428001
2022-01-30 14:52:04,071 valid_loss 0.749282
2022-01-30 14:52:04,073 |skip_connect~0|+|nor_conv_3x3~0|skip_connect~1|+|skip_connect~0|nor_conv_3x3~1|skip_connect~2|
datasets : ['cifar10-valid', 'cifar10', 'cifar100', 'ImageNet16-120'], extra-info : arch-index=11118
cifar10-valid  FLOP= 78.56 M, Params=0.559 MB, latency=14.43 ms.
cifar10-valid  train : [loss = 0.158, top1 = 94.87%], valid : [loss = 0.509, top1 = 84.89%]
cifar10        FLOP= 78.56 M, Params=0.559 MB, latency=14.68 ms.
cifar10        train : [loss = 0.171, top1 = 94.20%], test  : [loss = 0.385, top1 = 87.98%]
cifar100       FLOP= 78.57 M, Params=0.565 MB, latency=13.32 ms.
cifar100       train : [loss = 1.102, top1 = 68.28%], valid : [loss = 1.472, top1 = 59.73%], test : [loss = 1.482, top1 = 59.57%]
ImageNet16-120 FLOP= 19.65 M, Params=0.567 MB, latency=11.13 ms.
ImageNet16-120 train : [loss = 2.604, top1 = 34.63%], valid : [loss = 2.640, top1 = 33.87%], test : [loss = 2.682, top1 = 33.29%]
2022-01-30 14:52:04,073 cifar10 train 94.200000 test 87.980000
2022-01-30 14:52:04,073 cifar100 train 68.280000 valid 59.730000 test 59.570000
2022-01-30 14:52:04,074 imagenet16 train 34.630000 valid 33.870000 test 33.290000
